---
title: "PUBLICATION-SCRAPER REPORT"
author: "Parnika Khattri & Sherry Tee"
date: "2024-09-26"
output:
  html_document:
    toc: true
    toc_depth: 1
    css: styles.css
    number_sections: true
    theme: flatly
    highlight: tango
    fig_caption: true
---

# Preface

As an R user, have you ever wondered how efficiently academic outputs can be tracked and analyzed across various platforms? What if there was a way to automate the retrieval of publications and software outputs, reducing the time and effort researchers and administrators spend gathering this data? These are the questions that drove the development of Publication-Scraper. This R package enables users to collect and analyze research outputs, providing a more efficient approach to academic performance tracking.

This report is written as part of the ETC5543 research project, supervised by Rob Hyndman and Michael Lydeamore. Throughout the development of the package, we encountered various challenges, particularly in integrating data from different sources like ORCID, Google Scholar, and CRAN. These challenges, however, provided an opportunity to enhance our technical skills and refine our understanding of research automation.

We are grateful for the guidance and support provided by our supervisors, Rob Hyndman and Michael Lydeamore and our mentor, David Frazier, whose feedback and encouragement were essential to the success of this project. We hope this report offers valuable insights into the creation and application of Publication-Scraper and highlights its potential to streamline research output analysis for academic institutions.

# Abstract

This project focuses on analyzing and automating the retrieval of academic outputs using Publication-Scraper, an R package developed to streamline research evaluation. Academic contributions, whether in the form of publications or software outputs, play a critical role in shaping the productivity and impact of researchers. This package leverages ORCID IDs, Google Scholar profiles and CRAN (Comprehensive R Archive Network) data to automate the collection of academic outputs for researchers within the Monash EBS department.

The analysis assumes that publication counts and software downloads provide a reliable and straightforward measure of academic output and impact. Two primary areas of investigation were carried out: one focusing on automating the retrieval of these outputs and the other on visualizing the research productivity metrics. Utilising R for data manipulation and web scraping, the package enables the analysis of trends in research productivity by examining publication counts, software downloads, and related factors such as publication year and author activity.

The results from the analysis revealed significant patterns in research output, particularly highlighting prolific authors like Athanasios Pantelous and Rob J Hyndman, who lead in publication counts. The package also identified trends in research activity over time, with sharp increases in publication output during certain periods. Additionally, software packages such as fracdiff and tsfeatures were found to be frequently downloaded, indicating a strong focus on time series analysis within the department.

Overall, Publication-Scraper not only automates data collection but also provides valuable insights into the productivity and impact of academic work within Monash EBS.

KEY WORDS: Academic output analysis, ORCID, Google Scholar, CRAN download volume, R package, Web scraping

# Introduction

## **Background**

Academic profiles have become essential for managing and showcasing scholarly work. ORCID (Open Researcher and Contributor ID) provides a unique identifier for researchers, linking them to their publications and research contributions. ORCID is widely used across institutions, making it an ideal data source for publication retrieval. Similarly, Google Scholar offers a profile for researchers that includes citation counts, h-index, and publication history, which are valuable metrics for evaluating academic performance.Beyond traditional publications, CRAN (The Comprehensive R Archive Network) plays a pivotal role in the open-source community by hosting R packages. Academic departments, especially those focused on computational research, need to track software outputs alongside publications. By incorporating CRAN download statistics, achievement-scraper allows users to evaluate software impact in the same way they analyze traditional publications. The package is tailored to the Monash EBS department’s needs but can be extended for broader applications in research institutions and universities globally.

## **Motivation**

In academic environments, tracking research output is critical for evaluating individual and departmental performance. However, collecting this data particularly across large institutions, can be a time-consuming process. The publication-scraper package was created to address this challenge by automating the retrieval of academic outputs for faculty members using ORCID IDs and Google Scholar Ids. ORCID is widely adopted as a universal identifier for researchers, making it an ideal source for collecting publication and software data.

## **Goals & Objectives**

The primary objective of publication-scraper is to provide users with an efficient tool for scraping, cleaning and visualizing data related to academic outputs. It allows researchers and administrators to:

-   Retrieve all publications associated with an ORCID and SCHOLAR profile.
-   Scrape software outputs on CRAN.
-   Visualise key metrics such as the most prolific authors, most cited works and top-downloaded software.

# How to Install

The publication-scraper package can be installed from the R console. Simply run the following command:

# Package Design and Structure

-   Overview of Design The publication-scraper package is designed with a modular and flexible architecture, allowing staff in the EBS department to retrieve and analyze publication data efficiently. It is built using a combination of web scraping techniques, API integration, and data manipulation functions, ensuring that staff in the Monash EBS department can effortlessly extract data from ORCID, Google Scholar, and CRAN.

-   Core Functions The core functions of the publication-scraper package are:

-   get_publications_from_orcid(): Retrieves all publications associated with a given ORCID ID, providing access to the author’s complete list of works.

-   get_publications_from_scholar(): Collects publication data from Google Scholar profiles using the Scholar ID, gathering valuable metrics such as citation counts and publication history.

-   cran_all_pubs(): Extracts download statistics for CRAN packages, allowing users to evaluate software impact.

-get_all_publications(): Combines the results from ORCID, Google Scholar, and CRAN to provide a consolidated view of a researcher’s publications and software outputs.

-   Directory Structure

R/: Contains R scripts with functions to retrieve and process publication data. combine.R: Functions to fetch and combine publication data from ORCID and Google Scholar.

separate.R: Functions to fetch data separately from ORCID and Google Scholar. utils.R: Utility functions to search for CRAN package download statistics. data/: Contains datasets.

orcid_gsid.rda: This dataset includes ORCID and Google Scholar IDs manually gathered from Monash EBS researchers.

data-raw/: Scripts for preparing and cleaning raw datasets, used to generate orcid_gsid.rda.

inst/vignettes/: Holds the vignette explaining the package's functionalities and visualizations, offering examples on how to analyze top authors, publication trends, and software downloads.

vignettes/: Contains the same vignette in markdown format for ease of accessibility and understanding.

man/: Contains documentation files for each R script and dataset in the package.

tests/: Contains unit tests to ensure the correct functioning of the package. DESCRIPTION & NAMESPACE: These define package metadata (version, dependencies, etc.) and exported functions.

README.md: Provides a general overview of the package and guides users on installation and basic usage.

Report.Rmd: The detailed report of the project, including goals, objectives, and methodology.

-   Dependencies

The publication-scraper package relies on several R packages to deliver its functionality:

Data Manipulation and Cleaning: dplyr, tidyverse Web Scraping: rvest, xml2 API Integration: rorcid, scholar Data Visualization: ggplot2 Data Handling: tibble HTTP Requests: httr

# Methodology

The publication-scraper package employs a systematic approach to gather, clean, and analyze publication data:

Data Retrieval: Uses the rorcid and scholar packages to extract data from ORCID and Google Scholar. CRAN package data is collected using the pkgsearch package.

Data Cleaning: Applies dplyr functions to filter, clean, and standardize the data, ensuring accuracy and consistency.

Data Integration: Combines data from ORCID, Google Scholar, and CRAN to create a unified dataset, providing a comprehensive view of research outputs.

Data Visualization: Utilizes ggplot2 to create visual representations of the data, enabling insightful analysis of publication trends, author contributions, and software downloads.

# Implementation

# Example Usage

Here's an example demonstrating how to use the publication-scraper package:

```{r, echo=FALSE, eval=FALSE}
# Load the publication-scraper package
library(publicationscraper)

# Retrieve publications for a specific ORCID ID
orcid_pubs <- get_publications_from_orcid("0000-0002-2140-5352")

# Retrieve publications for a specific Google Scholar ID
scholar_pubs <- get_publications_from_scholar("vamErfkAAAAJ")

# Combine publications from both ORCID and Scholar
all_pubs <- get_all_publications(data.frame(orcid_id = "0000-0002-2140-5352", scholar_id = "vamErfkAAAAJ"))

# Retrieve CRAN package download statistics
cran_data <- cran_all_pubs(data.frame(first_name = "Michael", last_name = "Hyndman"))

```

# Documentation and User Guide

# Future Work and Extensions - Some sort of reflection on how successful you were and possible next steps

The publication-scraper package has successfully streamlined the process of retrieving and analyzing academic outputs from ORCID, Google Scholar, and CRAN, offering a comprehensive tool for tracking research productivity at Monash EBS. However, there are several potential extensions to enhance its functionality:

-Improved Data Cleaning: While the package effectively retrieves publication data, there are instances of missing or incomplete author information. Future iterations could include more robust cleaning functions to handle missing data more effectively, possibly utilizing external databases to fill in gaps.

-   Automation of Dataset Updates: Automating the updating of ORCID and Google Scholar IDs would further streamline the process and ensure the dataset remains up-to-date without manual intervention.

-   Cross-Institutional Comparison: Expanding the package to handle data from multiple institutions could make it possible to perform benchmarking and cross-institutional comparisons. This would be especially useful for academic departments wanting to compare their performance with peer institutions, fostering a competitive research environment.

-   Interactive Dashboards: Developing an interactive dashboard using R packages like Shiny would provide a more dynamic user experience. Users could filter data, explore trends, and generate custom reports in real-time, making the analysis process more intuitive and accessible, especially for non-technical users like administrators.

# Result & Conclusion - A clear description of your contributions

The publication-scraper project was structured to ensure a clear and balanced division of work between Parnika and Sherry, with valuable guidance from our hosts Michael and Rob, who provided support in our guidance of work and resolving bugs throughout the project. On the other hand, David played a pivotal role in providing mental support throughout the project, consistently checking in on progress and offering valuable tips on improving the final report writing.

The work began by preparing the dataset, a crucial component of the package. Parnika manually inputted the ORCID IDs of Monash EBS staff, while Sherry handled the task of inputting the corresponding Google Scholar IDs.

Sherry developed the core functions of the package, such as get_publications_from_orcid(), get_publications_from_scholar(), and get_all_publications(), which retrieve and combine publication data from ORCID, Google Scholar, and CRAN. Parnika provided examples that demonstrated how these functions can be applied, ensuring that the package is user-friendly.

Both Parnika and Sherry collaborated on creating the vignettes, offering practical insights and visualizations on top authors, publication trends, and software downloads. Parnika took responsibility for writing and executing the unit tests to ensure the functions performed correctly and contributed significantly to the documentation. Sherry finalized the project by writing the README file, which provides an overview of the package, along with installation and usage instructions.

Throughout the project, Michael and Rob provided critical guidance, particularly in addressing technical issues and ensuring the package's functionality.David's continuous encouragement and input on improving the report further enhanced the quality of the final deliverable. Their input greatly contributed to the project’s success.

The work was evenly distributed, with each team member contributing to different components of the project. Through collaboration and the support of their hosts, Parnika and Sherry successfully created a robust and functional tool for analyzing academic outputs at Monash EBS. The publication-scraper stands as a solid foundation for future development and extensions.

# References

# Appendix(if required)
