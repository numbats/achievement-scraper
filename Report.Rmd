---
title: "PUBLICATION-SCRAPER REPORT"
author: "Parnika Khattri & Sherry Tee"
date: "2024-09-26"
output: html_document
---

# Abstract 

The publication-scraper is an R package designed to efficiently retrieve and analyse the academic outputs of researchers, with a particular focus on publications and software outputs. Tailored to meet the specific needs of the Monash EBS department, the package streamlines the process of collecting data for research evaluation and performance tracking. By utilising ORCID IDs, Google Scholar IDs and CRAN package information as inputs, publication-scraper automates the retrieval of publications, software downloads and other research contributions, providing users with a comprehensive and effective tool for academic analysis. The package is designed to support research administrators, faculty members and analysts in generating insights into academic productivity and impact.

# Introduction

-   **Background**

Academic profiles have become essential for managing and showcasing scholarly work. ORCID (Open Researcher and Contributor ID) provides a unique identifier for researchers, linking them to their publications and research contributions. ORCID is widely used across institutions, making it an ideal data source for publication retrieval. Similarly, Google Scholar offers a profile for researchers that includes citation counts, h-index, and publication history, which are valuable metrics for evaluating academic performance.Beyond traditional publications, CRAN (The Comprehensive R Archive Network) plays a pivotal role in the open-source community by hosting R packages. Academic departments, especially those focused on computational research, need to track software outputs alongside publications. By incorporating CRAN download statistics, achievement-scraper allows users to evaluate software impact in the same way they analyze traditional publications. The package is tailored to the Monash EBS department’s needs but can be extended for broader applications in research institutions and universities globally.

-   **Motivation**

In academic environments, tracking research output is critical for evaluating individual and departmental performance. However, collecting this data particularly across large institutions, can be a time-consuming process. The publication-scraper package was created to address this challenge by automating the retrieval of academic outputs for faculty members using ORCID IDs and Google Scholar Ids. ORCID is widely adopted as a universal identifier for researchers, making it an ideal source for collecting publication and software data.

-   **Goals & Objectives**

The primary objective of publication-scraper is to provide users with an efficient tool for scraping, cleaning and visualizing data related to academic outputs. It allows researchers and administrators to:

-   Retrieve all publications associated with an ORCID and SCHOLAR profile.
-   Scrape software outputs on CRAN.
-   Visualise key metrics such as the most prolific authors, most cited works and top-downloaded software.

# Package Design and Structure 

-   Overview of Design
The publication-scraper package is designed with a modular and flexible architecture, allowing staff in the EBS department to retrieve and analyze publication data efficiently. It is built using a combination of web scraping techniques, API integration, and data manipulation functions, ensuring that staff in the Monash EBS department can effortlessly extract data from ORCID, Google Scholar, and CRAN.

-   Core Functions
The core functions of the publication-scraper package are:

- get_publications_from_orcid(): Retrieves all publications associated with a given ORCID ID, providing access to the author’s complete list of works.

- get_publications_from_scholar(): Collects publication data from Google Scholar profiles using the Scholar ID, gathering valuable metrics such as citation counts and publication history.

- cran_all_pubs(): Extracts download statistics for CRAN packages, allowing users to evaluate software impact.

-get_all_publications(): Combines the results from ORCID, Google Scholar, and CRAN to provide a consolidated view of a researcher’s publications and software outputs.

-   Directory Structure

R/: Contains R scripts with functions to retrieve and process publication data.
combine.R: Functions to fetch and combine publication data from ORCID and Google Scholar.

separate.R: Functions to fetch data separately from ORCID and Google Scholar.
utils.R: Utility functions to search for CRAN package download statistics.
data/: Contains datasets.

orcid_gsid.rda: This dataset includes ORCID and Google Scholar IDs manually gathered from Monash EBS researchers.

data-raw/: Scripts for preparing and cleaning raw datasets, used to generate orcid_gsid.rda.

inst/vignettes/: Holds the vignette explaining the package's functionalities and visualizations, offering examples on how to analyze top authors, publication trends, and software downloads.

vignettes/: Contains the same vignette in markdown format for ease of accessibility and understanding.

man/: Contains documentation files for each R script and dataset in the package.

tests/: Contains unit tests to ensure the correct functioning of the package.
DESCRIPTION & NAMESPACE: These define package metadata (version, dependencies, etc.) and exported functions.

README.md: Provides a general overview of the package and guides users on installation and basic usage.

Report.Rmd: The detailed report of the project, including goals, objectives, and methodology.


-   Dependencies

The publication-scraper package relies on several R packages to deliver its functionality:

Data Manipulation and Cleaning: dplyr, tidyverse
Web Scraping: rvest, xml2
API Integration: rorcid, scholar
Data Visualization: ggplot2
Data Handling: tibble
HTTP Requests: httr

# Methodology

The publication-scraper package employs a systematic approach to gather, clean, and analyze publication data:

Data Retrieval: Uses the rorcid and scholar packages to extract data from ORCID and Google Scholar. CRAN package data is collected using the pkgsearch package.

Data Cleaning: Applies dplyr functions to filter, clean, and standardize the data, ensuring accuracy and consistency.

Data Integration: Combines data from ORCID, Google Scholar, and CRAN to create a unified dataset, providing a comprehensive view of research outputs.

Data Visualization: Utilizes ggplot2 to create visual representations of the data, enabling insightful analysis of publication trends, author contributions, and software downloads.

# Implementation

# Example Usage

Here's an example demonstrating how to use the publication-scraper package:
```{r}
# Load the publication-scraper package
library(publicationscraper)

# Retrieve publications for a specific ORCID ID
orcid_pubs <- get_publications_from_orcid("0000-0002-2140-5352")

# Retrieve publications for a specific Google Scholar ID
scholar_pubs <- get_publications_from_scholar("vamErfkAAAAJ")

# Combine publications from both ORCID and Scholar
all_pubs <- get_all_publications(data.frame(orcid_id = "0000-0002-2140-5352", scholar_id = "vamErfkAAAAJ"))

# Retrieve CRAN package download statistics
cran_data <- cran_all_pubs(data.frame(first_name = "Michael", last_name = "Hyndman"))

```


# Documentation and User Guide

# Future Work and Extensions - Some sort of reflection on how successful you were and possible next steps

The publication-scraper package has successfully streamlined the process of retrieving and analyzing academic outputs from ORCID, Google Scholar, and CRAN, offering a comprehensive tool for tracking research productivity at Monash EBS. However, there are several potential extensions to enhance its functionality:

-Improved Data Cleaning: While the package effectively retrieves publication data, there are instances of missing or incomplete author information. Future iterations could include more robust cleaning functions to handle missing data more effectively, possibly utilizing external databases to fill in gaps.

- Automation of Dataset Updates: Automating the updating of ORCID and Google Scholar IDs would further streamline the process and ensure the dataset remains up-to-date without manual intervention.

- Cross-Institutional Comparison: Expanding the package to handle data from multiple institutions could make it possible to perform benchmarking and cross-institutional comparisons. This would be especially useful for academic departments wanting to compare their performance with peer institutions, fostering a competitive research environment.

- Interactive Dashboards: Developing an interactive dashboard using R packages like Shiny would provide a more dynamic user experience. Users could filter data, explore trends, and generate custom reports in real-time, making the analysis process more intuitive and accessible, especially for non-technical users like administrators.


# Result & Conclusion - A clear description of your contributions
The publication-scraper project was structured to ensure a clear and balanced division of work between Parnika and Sherry, with valuable guidance from our hosts Michael and Rob, who provided support in our guidance of work and resolving bugs throughout the project. On the other hand, David played a pivotal role in providing mental support throughout the project, consistently checking in on progress and offering valuable tips on improving the final report writing. 

The work began by preparing the dataset, a crucial component of the package. Parnika manually inputted the ORCID IDs of Monash EBS staff, while Sherry handled the task of inputting the corresponding Google Scholar IDs.

Sherry developed the core functions of the package, such as get_publications_from_orcid(), get_publications_from_scholar(), and get_all_publications(), which retrieve and combine publication data from ORCID, Google Scholar, and CRAN. Parnika provided examples that demonstrated how these functions can be applied, ensuring that the package is user-friendly.

Both Parnika and Sherry collaborated on creating the vignettes, offering practical insights and visualizations on top authors, publication trends, and software downloads. Parnika took responsibility for writing and executing the unit tests to ensure the functions performed correctly and contributed significantly to the documentation. Sherry finalized the project by writing the README file, which provides an overview of the package, along with installation and usage instructions.

Throughout the project, Michael and Rob provided critical guidance, particularly in addressing technical issues and ensuring the package's functionality.David's continuous encouragement and input on improving the report further enhanced the quality of the final deliverable. Their input greatly contributed to the project’s success.

The work was evenly distributed, with each team member contributing to different components of the project. Through collaboration and the support of their hosts, Parnika and Sherry successfully created a robust and functional tool for analyzing academic outputs at Monash EBS. The publication-scraper stands as a solid foundation for future development and extensions.

# References

# Appendix(if required)

-   Vignettes
